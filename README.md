# Meeting AI Assistant â€“ Report Generator

Ce projet permet de gÃ©nÃ©rer des **rapports de rÃ©union** Ã  partir de fichiers audio.

Lâ€™application permet :

- ğŸ“ **Transcription automatique** de rÃ©unions (via OpenAI, modÃ¨le ASR)
- ğŸ§‘â€ğŸ¤â€ğŸ§‘ **Segmentation par locuteurs (diarisation simple)** par alternance en fonction des pauses
- ğŸ“Š **GÃ©nÃ©ration de notes structurÃ©es** : sujets, dÃ©cisions, actions
- ğŸ“„ **Export des rapports** au format **Markdown** et **PDF**
- ğŸ’» **Interface Streamlit** pour tester le flux de bout en bout

---

## 1. Stack technique

- **Backend** : FastAPI (Python 3.11)
- **Frontend** : Streamlit
- **Transcription audio** : OpenAI Audio API (modÃ¨le `gpt-4o-mini-transcribe` ou Whisper compatible)
- **Traitement audio** : `pydub` + `ffmpeg`
- **GÃ©nÃ©ration de rÃ©sumÃ©** : OpenAI Chat Completions (`gpt-4o-mini`)
- **Exports** :
  - Markdown : rendu manuel
  - PDF : `reportlab` avec un template structurÃ©

---

## 2. Architecture gÃ©nÃ©rale

### 2.1. Vue dâ€™ensemble

- `main.py`  
  Point dâ€™entrÃ©e FastAPI (inclusion des routers, CORS, config).

- `app/api/reports.py`  
  Endpoints pour :
  - `/reports/transcribe` : transcription pure
  - `/reports/notes` : gÃ©nÃ©ration des notes + fichiers dâ€™export
  - `/reports/files/{report_id}/{filename}` : tÃ©lÃ©chargement des fichiers gÃ©nÃ©rÃ©s

- `app/services/transcription.py`  
  Logique de transcription audio :
  - chargement + resampling audio (`pydub`)
  - dÃ©coupage en chunks
  - appel Ã  lâ€™API OpenAI
  - reconstruction du texte + segments (timestamps)

- `app/services/notes.py`  
  GÃ©nÃ©ration et export des notes :
  - `generate_structured_notes()` : prompt + appel OpenAI pour structurer le compte-rendu
  - `render_markdown()` : construction du Markdown
  - `generate_pdf_report()` : crÃ©ation dâ€™un PDF â€œpropreâ€ (rÃ©sumÃ©, sujets, dÃ©cisions, actions, transcription)

- `app/models/notes.py`  
  Schemas Pydantic pour :
  - `MeetingSummary` (executive summary, topics, decisions, actions)
  - `NotesResponse`

- `app/schemas/reports.py`  
  Schemas de rÃ©ponse pour `/reports/transcribe`.

- `streamlit_app.py`  
 Interface utilisateur :
  - upload dâ€™un fichier audio
  - bouton â€œTranscriptionâ€
  - bouton â€œGÃ©nÃ©rer les notesâ€
  - boutons de tÃ©lÃ©chargement Markdown / PDF

---

## 3. Installation & configuration

### 3.1. PrÃ©requis

- Python 3.11+
- Docker & Docker Compose 

### 3.2. Variables dâ€™environnement

CrÃ©er un fichier `.env` Ã  la racine :
```env
DEBUG=true
SECRET_KEY=secret
DB_ENGINE=sqlite  # or postgresql
# For PostgreSQL, add these:
# DB_USER=postgres
# DB_PASSWORD=password
# DB_HOST=localhost
# DB_PORT=5432
# DB_NAME=app
#HUGGINGFACE_TOKEN=XXXXXXXXXXXX
#BACKEND=hf
OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXX
BACKEND=openai
#ASR_MODEL_ID=gpt-4o-mini-transcribe 
ASR_MODEL_ID=whisper-1
```

## Docker

The project includes Docker configurations for both development and production:

- `docker-compose.yml`: Production setup
- `docker-compose.dev.yml`: Development setup with hot-reload
## 4ï¸. Utilisation

### Lancer le backend FastAPI avec Docker

```bash
docker compose -f docker-compose.dev.yml up --build
```
### Lancer lâ€™interface Streamlit
```
streamlit run streamlit_app.py
```

## Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b ft/my-feature`
3. Commit your changes: `git commit -m 'Add my feature'`
4. Push to the branch: `git push origin ft/my-feature`

## AperÃ§u du projet

Voici quelques captures dâ€™Ã©cran illustrant le fonctionnement de lâ€™application :

### ğŸ”¹ Interface Streamlit â€“ Transcription Audio
![Interface Streamlit](images/1.png)

### ğŸ”¹ RÃ©sumÃ© StructurÃ© du Rapport (PDF)
![RÃ©sumÃ© StructurÃ©](images/pdf1.png)

### ğŸ”¹ DÃ©tails du Rapport (DÃ©cisions, Actions, Transcript)
![Rapport dÃ©taillÃ©](images/pdf2.png)

### ğŸ”¹ DÃ©tails du Markdown (DÃ©cisions, Actions, Transcript)
![Rapport dÃ©taillÃ©](images/3.png)
